{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPrUMBFo3tzpUO97qJsmX59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inhamtool/Multi-Comment-Sentiment-Analyzer---Model/blob/main/multilevelsympathizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xluCk_cqblJx",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install gradio transformers requests beautifulsoup4 textblob\n",
        "\n",
        "# Imports\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "import numpy as np\n",
        "\n",
        "# Load sentiment pipeline\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        ")\n",
        "\n",
        "# Improved text extraction with comment collection\n",
        "def extract_comments_from_url(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        comments = []\n",
        "\n",
        "        # Try to find comment sections (common patterns)\n",
        "        comment_selectors = [\n",
        "            '[class*=\"comment\"]',\n",
        "            '[class*=\"review\"]',\n",
        "            '[class*=\"user-content\"]',\n",
        "            '[class*=\"user-text\"]',\n",
        "            '.comment-text',\n",
        "            '.review-text',\n",
        "            '.user-comment',\n",
        "            '.comment-content',\n",
        "            '.review-content',\n",
        "            '.comment-body'\n",
        "        ]\n",
        "\n",
        "        for selector in comment_selectors:\n",
        "            elements = soup.select(selector)\n",
        "            for element in elements:\n",
        "                comment_text = element.get_text(strip=True)\n",
        "                if len(comment_text) > 20:  # Only take substantial comments\n",
        "                    comments.append(comment_text)\n",
        "\n",
        "        # If no specific comments found, try to extract paragraphs as individual comments\n",
        "        if len(comments) < 3:\n",
        "            paragraphs = soup.find_all('p')\n",
        "            for p in paragraphs:\n",
        "                p_text = p.get_text(strip=True)\n",
        "                if len(p_text) > 30 and len(p_text) < 500:  # Reasonable comment length\n",
        "                    comments.append(p_text)\n",
        "\n",
        "        # Remove duplicates and clean\n",
        "        comments = list(set(comments))\n",
        "        comments = [c for c in comments if len(c) > 10]\n",
        "\n",
        "        return comments[:20]  # Limit to 20 comments max\n",
        "\n",
        "    except Exception as e:\n",
        "        return [f\"Error: Could not extract comments - {str(e)}\"]\n",
        "\n",
        "# Enhanced sentiment analysis for multiple comments\n",
        "def analyze_comments(input_text_or_url):\n",
        "    # Determine if input is URL or text\n",
        "    if input_text_or_url.startswith(\"http\"):\n",
        "        if \"imdb.com\" in input_text_or_url and \"/video/\" in input_text_or_url:\n",
        "            return \"âŒ Video pages don't have comments. Try IMDb review pages instead!\"\n",
        "\n",
        "        comments = extract_comments_from_url(input_text_or_url)\n",
        "        if not comments or \"Error\" in comments[0]:\n",
        "            return f\"âŒ Could not extract comments from this page. Please try a different URL or paste comments directly.\"\n",
        "\n",
        "        source_info = f\"ðŸ“Š Analyzed {len(comments)} comments from the webpage\"\n",
        "\n",
        "    else:\n",
        "        # Split text input by lines or periods to get multiple comments\n",
        "        text = input_text_or_url\n",
        "        # Split by newlines first, then by sentences if needed\n",
        "        if '\\n' in text:\n",
        "            comments = [line.strip() for line in text.split('\\n') if len(line.strip()) > 10]\n",
        "        else:\n",
        "            # Split by sentences\n",
        "            comments = [s.strip() for s in text.split('.') if len(s.strip()) > 10]\n",
        "\n",
        "        if len(comments) < 2:\n",
        "            return \"âŒ Please provide multiple comments (separated by newlines) or a webpage with comments for comparison.\"\n",
        "\n",
        "        source_info = f\"ðŸ“Š Analyzed {len(comments)} comments from your input\"\n",
        "\n",
        "    if len(comments) < 2:\n",
        "        return \"âŒ Not enough comments found for comparison. Please provide more content.\"\n",
        "\n",
        "    # Analyze each comment\n",
        "    results = []\n",
        "    sentiment_counts = {\"positive\": 0, \"negative\": 0, \"neutral\": 0}\n",
        "    confidence_scores = []\n",
        "\n",
        "    for i, comment in enumerate(comments[:15]):  # Limit to 15 comments for performance\n",
        "        try:\n",
        "            result = sentiment_pipeline(comment[:400])[0]  # Shorter limit for multiple comments\n",
        "            label = result['label']\n",
        "            score = result['score']\n",
        "\n",
        "            # Classify sentiment\n",
        "            if \"1 star\" in label or \"2 stars\" in label:\n",
        "                sentiment = \"negative\"\n",
        "                emoji = \"ðŸ‘Ž\"\n",
        "            elif \"3 stars\" in label:\n",
        "                sentiment = \"neutral\"\n",
        "                emoji = \"ðŸ˜\"\n",
        "            elif \"4 stars\" in label or \"5 stars\" in label:\n",
        "                sentiment = \"positive\"\n",
        "                emoji = \"ðŸ‘\"\n",
        "            else:\n",
        "                sentiment = \"neutral\"\n",
        "                emoji = \"ðŸ¤”\"\n",
        "\n",
        "            sentiment_counts[sentiment] += 1\n",
        "            confidence_scores.append(score)\n",
        "\n",
        "            results.append({\n",
        "                \"comment\": comment[:100] + \"...\" if len(comment) > 100 else comment,\n",
        "                \"sentiment\": sentiment,\n",
        "                \"emoji\": emoji,\n",
        "                \"confidence\": score\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            continue  # Skip comments that fail analysis\n",
        "\n",
        "    if not results:\n",
        "        return \"âŒ Could not analyze any comments. Please try different content.\"\n",
        "\n",
        "    # Calculate overall statistics\n",
        "    total = len(results)\n",
        "    positive_pct = (sentiment_counts[\"positive\"] / total) * 100\n",
        "    negative_pct = (sentiment_counts[\"negative\"] / total) * 100\n",
        "    neutral_pct = (sentiment_counts[\"neutral\"] / total) * 100\n",
        "    avg_confidence = np.mean(confidence_scores) * 100\n",
        "\n",
        "    # Determine overall reaction\n",
        "    if positive_pct > 60:\n",
        "        overall = \"OVERWHELMINGLY POSITIVE ðŸŽ‰\"\n",
        "        reaction_emoji = \"ðŸ˜\"\n",
        "        summary = \"People loved this content! The majority had very positive things to say.\"\n",
        "    elif positive_pct > 40:\n",
        "        overall = \"MOSTLY POSITIVE ðŸ˜Š\"\n",
        "        reaction_emoji = \"ðŸ™‚\"\n",
        "        summary = \"The general reaction was positive. More people liked it than didn't.\"\n",
        "    elif negative_pct > 60:\n",
        "        overall = \"OVERWHELMINGLY NEGATIVE ðŸ˜ž\"\n",
        "        reaction_emoji = \"ðŸ˜ \"\n",
        "        summary = \"People were not happy with this content. The majority had negative feedback.\"\n",
        "    elif negative_pct > 40:\n",
        "        overall = \"MOSTLY NEGATIVE ðŸ‘Ž\"\n",
        "        reaction_emoji = \"ðŸ˜\"\n",
        "        summary = \"The general reaction was negative. More people had issues than praised it.\"\n",
        "    elif neutral_pct > 50:\n",
        "        overall = \"MIXED/NEUTRAL ðŸ¤”\"\n",
        "        reaction_emoji = \"ðŸ¤·\"\n",
        "        summary = \"People had mixed feelings. No strong consensus either way.\"\n",
        "    else:\n",
        "        overall = \"DIVIDED OPINIONS âš–ï¸\"\n",
        "        reaction_emoji = \"âš–ï¸\"\n",
        "        summary = \"The audience is split between positive and negative reactions.\"\n",
        "\n",
        "    # Build detailed report\n",
        "    report = f\"\"\"\n",
        "{reaction_emoji} **OVERALL REACTION: {overall}**\n",
        "\n",
        "{summary}\n",
        "\n",
        "{source_info}\n",
        "---\n",
        "\n",
        "ðŸ“ˆ **SENTIMENT BREAKDOWN:**\n",
        "âœ… Positive: {sentiment_counts['positive']} comments ({positive_pct:.1f}%)\n",
        "âŒ Negative: {sentiment_counts['negative']} comments ({negative_pct:.1f}%)\n",
        "âš–ï¸ Neutral: {sentiment_counts['neutral']} comments ({neutral_pct:.1f}%)\n",
        "\n",
        "ðŸŽ¯ Analysis Confidence: {avg_confidence:.1f}%\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ’¬ **SAMPLE COMMENTS:**\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Add sample comments from each category\n",
        "    for sentiment_type in [\"positive\", \"negative\", \"neutral\"]:\n",
        "        type_comments = [r for r in results if r[\"sentiment\"] == sentiment_type]\n",
        "        if type_comments:\n",
        "            if sentiment_type == \"positive\":\n",
        "                report += f\"**ðŸ‘ Positive Comments:**\\n\"\n",
        "            elif sentiment_type == \"negative\":\n",
        "                report += f\"**ðŸ‘Ž Negative Comments:**\\n\"\n",
        "            else:\n",
        "                report += f\"**ðŸ˜ Neutral Comments:**\\n\"\n",
        "\n",
        "            for i, result in enumerate(type_comments[:2]):  # Show 2 examples per type\n",
        "                report += f\"{i+1}. {result['emoji']} \\\"{result['comment']}\\\"\\n\"\n",
        "            report += \"\\n\"\n",
        "\n",
        "    report += f\"\\---\\n**ðŸ’¡ Insight:** \"\n",
        "\n",
        "    if positive_pct > 70:\n",
        "        report += \"This content really resonated with the audience!\"\n",
        "    elif negative_pct > 70:\n",
        "        report += \"There are significant issues that need addressing.\"\n",
        "    elif neutral_pct > 50:\n",
        "        report += \"The content didn't strongly impress or disappoint most people.\"\n",
        "    else:\n",
        "        report += \"Opinions are varied - different people had different experiences.\"\n",
        "\n",
        "    return report\n",
        "\n",
        "# Build the enhanced UI\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_comments,\n",
        "    inputs=gr.Textbox(\n",
        "        lines=10,\n",
        "        placeholder=\"Paste multiple comments (one per line) OR a webpage URL with comments...\\n\\nExamples:\\nâ€¢ 'Amazing movie! Best of the year!\\\\nTerrible acting, would not recommend.\\\\nIt was okay, nothing special.'\\nâ€¢ https://www.imdb.com/title/tt0111161/reviews/\\nâ€¢ Any news article or blog post with comments\",\n",
        "        label=\"Enter Multiple Comments or Website URL\"\n",
        "    ),\n",
        "    outputs=gr.Textbox(\n",
        "        lines=15,\n",
        "        label=\"Audience Reaction Analysis\",\n",
        "        show_copy_button=True\n",
        "    ),\n",
        "    title=\"ðŸŽ¬ Multi-Comment Sentiment Analyzer\",\n",
        "    description=\"Analyze multiple comments together to understand overall audience reaction! Paste comments (one per line) or a webpage URL with comments.\",\n",
        "    examples=[\n",
        "        [\"Loved this movie! Great acting.\\nThe plot was boring and predictable.\\nAmazing visuals but weak story.\\nBest film I've seen this year!\\nNot worth the money, very disappointed.\"],\n",
        "        [\"https://www.imdb.com/title/tt0111161/reviews/\"],\n",
        "        [\"Outstanding performance by all actors.\\nThe cinematography was breathtaking.\\nSome scenes felt too long and dragged.\\nExcellent direction and screenplay.\\nAverage movie, expected more.\"]\n",
        "    ],\n",
        "    theme=\"soft\"\n",
        ")\n",
        "\n",
        "# Launch UI\n",
        "iface.launch(share=True)"
      ]
    }
  ]
}